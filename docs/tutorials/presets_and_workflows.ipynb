{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presets and Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial index\n",
    "* <a href=\"./introduction.ipynb\">Introduction to BioProv</a>\n",
    "* <a href=\"./w3c-prov.ipynb\">W3C-PROV projects</a>\n",
    "* <a href=\"./workflows_and_presets.ipynb\">Presets and Workflows</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we're gonna take a look at how to build preset programs and workflows in order to accelerate the development of provenance-aware pipelines.\n",
    "\n",
    "This will be done using the PresetProgram and Workflow classes made available by BioProv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preset programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed before, manually creating programs is something that BioProv supports and encourages. But it might become a too repetitive if you find yourself using the same command structure frequently, therefore we provide the class PresetProgram, which facilitates creation of programs using a single object and makes it very easy to generalize the same program structure for running it in batches as well as building workflows with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, it's good to know that BioProv already provides a series of different preset programs for common bioinformatics tasks, here is a list of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioprov.programs\n",
    "from inspect import getmembers, isfunction\n",
    "\n",
    "getmembers(bioprov.programs, isfunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't find the program you want in the list above, don't fret! We're gonna show you how to build your own next.\n",
    "\n",
    "First, let's read in the example data we've been using, as well as a blastdb for a subset of the [MegaRes database](https://megares.meglab.org/) made available through our data module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioprov as bp\n",
    "from bioprov import Sample\n",
    "from bioprov.data import synechococcus_genome, megares_blastdb\n",
    "\n",
    "example_genome = Sample(\"Synechococcus\", files={\"assembly\": synechococcus_genome})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's say, for demonstration purposes, that BioProv doesn't have a BlastN preset program but we still wish to align each of these genomes to the MegaRes BlastDB.\n",
    "\n",
    "To do that, we can go one of two paths: Manually creating the program object for BlastN in a script or, if we think this is a process we'll run many times over different days across various genomes, it might be wise to create a PresetProgram for it. We'll show you how to do the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this you will need BlastN installed, which can be easily done through the [conda package manager](https://anaconda.org/bioconda/blast):\n",
    "```bash\n",
    "conda install blast -c bioconda\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioprov.src.main import Parameter, PresetProgram\n",
    "\n",
    "blastn = PresetProgram(\n",
    "        name=\"blastn\",\n",
    "        params=(\n",
    "            Parameter(key=\"-db\", value=megares_blastdb),\n",
    "            # outfmt 6 is the blastn tabular output format\n",
    "            Parameter(key=\"-outfmt\", value=6),\n",
    "        ),\n",
    "        sample=example_genome,\n",
    "        input_files={\"-query\": \"assembly\"},\n",
    "        output_files={\"-out\": (\"megares_hits\", \"_megares_hits.txt\")}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, maybe that was a lot, let's break down what\n",
    "PresetPrograms take in:\n",
    "1. The program name, in this case `blastn`\n",
    "\n",
    "2. Some general parameters and corresponding values that will be used, defined through the `params` arguments.\n",
    "\n",
    "3. The input parameter, `-query` in this case, and the corresponding tag for the input sample, which we defined as 'assembly'.\n",
    "\n",
    "4. The output parameter, `-out` in this case, as well as a tag and a suffix for the output file. The tag will be added to the the sample's files and the output parameter value will correspond to the sample name + the suffix.\n",
    "\n",
    "We can also define the `extra_flags` argument, which is used to append extra command line parameters (flags or switches) to the end of the command string.\n",
    "\n",
    "Though less flexible than manually adding Files and Parameters as we saw for the Program class in the introductory tutorial, PresetPrograms support the general structure of most command line tools and help accelerate development as well as maintain the codebase shorter and easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can then run this program the same way we would with any other one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blastn.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then see the output file gets added to our Sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_genome.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn this preset into a function that takes in only the sample, just so it's more reusable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_to_megares(assembly_sample):\n",
    "    \n",
    "    blastn = PresetProgram(\n",
    "        name=\"blastn\",\n",
    "        params=(\n",
    "            Parameter(key=\"-db\", value=megares_blastdb),\n",
    "            # outfmt 6 is the blastn tabular output format\n",
    "            Parameter(key=\"-outfmt\", value=6),\n",
    "        ),\n",
    "        sample=assembly_sample,\n",
    "        input_files={\"-query\": \"assembly\"},\n",
    "        output_files={\"-out\": (\"megares_hits\", \"_megares_hits.txt\")}\n",
    "    )\n",
    "    \n",
    "    return blastn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But then, let's suppose aligning to MegaRes is only the first step in a series of commands (or pipeline) we routinely run in our work.\n",
    "\n",
    "What we're describing here is a Workflow and BioProv provides a helper class to deal with this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say the next step could be filtering the hits we obtained by their score and saving the filtered data. For this purpose, we could use an [AWK](https://en.wikipedia.org/wiki/Awk) command, so, let's build a PresetProgram for this task too! In this case, we'll use the output tag from the previous step as our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_high_score(alignment_sample):\n",
    "    \n",
    "    score_filter = PresetProgram(\n",
    "        name=\"awk\",\n",
    "        # Parameters can be ommitted!\n",
    "        sample=alignment_sample,\n",
    "        # Score greater or equal to 1000\n",
    "        input_files={\"'$12>=1000'\": \"megares_hits\"},\n",
    "        output_files={\">\": (\"high_score\", \"_high_score_hits.txt\")}\n",
    "    )\n",
    "    \n",
    "    return score_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's start building a workflow using the two presets we've made.\n",
    "\n",
    "First thing we'll need is a dataset to use as input for the workflow, for that we'll use the `picocyano_dataset`, only altering the paths in the 'assembly' column to be the relative paths to their respective files. The workflow will run on all samples created from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioprov.data import picocyano_dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(picocyano_dataset)\n",
    "\n",
    "df[\"assembly\"] = \"../../\" + df[\"assembly\"]\n",
    "\n",
    "df.to_csv(path_or_buf=\"test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can begin building the workflow itself, BioProv Workflow objects take in a lot of parameters (run `help(Workflow)` to see a list of them), the ones we'll be using today are:\n",
    "\n",
    "1. `name`: The name we'll choose for this workflow;\n",
    "\n",
    "2. `description`: A description for the workflow;\n",
    "\n",
    "3. `input`, `sep`: The input for the workflow. Since the input is a tabular data file, it's good to specify the column separator (it defaults to tabs);\n",
    "\n",
    "4. `input_type`: The type of input the workflow expects, it can be dataframe (a path to a tabular data file), a path to a directory of files or both.\n",
    "\n",
    "5. `index_col`, `file_columns`: These should be familiar to you if you've looked at the previous tutorials. It merely indicates what are the relevant portions of the dataframe to create the project with. \n",
    "\n",
    "6. `write_provn`: In case we want to write the PROVN document after running the workflow. Let's set it to true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bioprov.src.workflow import Workflow, Step\n",
    "\n",
    "get_megares_hits = Workflow(\n",
    "    name=\"Get best MegaRes hits\",\n",
    "    description=\"Align nucleotide data to MegaRes with BLASTN and filters high-score (>=1000) hits.\",\n",
    "    input='./test_dataset.csv',\n",
    "    sep=\",\",\n",
    "    input_type=\"dataframe\",\n",
    "    index_col=\"sample-id\",\n",
    "    file_columns=\"assembly\",\n",
    "    write_provn=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this workflow isn't associated with any particular project, you can see BioProv generated a project using a random tag.\n",
    "\n",
    "Now let's add the steps to this workflow using the PresetProgram functions we built before. You might think it's strange we're setting the samples to None, but this is just so the function returns a PresetProgram instance, which the Workflow expects, the samples will be injected from the dataset we used as input for the workflow (so it won't be None in the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    Step(align_to_megares(None), default=True),\n",
    "    Step(filter_high_score(None), default=True),\n",
    "]\n",
    "\n",
    "for _step in steps:\n",
    "        get_megares_hits.add_step(_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then choose which steps we want to run using a list as input to the `run_steps` method. They will then run in the order they were added to the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_megares_hits.run_steps(['blastn', 'awk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that was a lot of stuff! But, if you look into this tutorial's directory, you will see a list of outputs corresponding to each step of the workflow, which ran for each file in the input dataset, as well as two other files:\n",
    "\n",
    "1. A PROVN file describing the whole workflow and the programs we just ran.\n",
    "\n",
    "2. A .log file similar to the cell output you see above, describing each command that was run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But anyway, that's it for presets and workflows in BioProv. We hope this inspires you to create your own provenance-aware programs and workflows. If you do, share it with us! \n",
    "\n",
    "And if you think the workflow or preset you created would be useful to others, feel free to strike a conversation in our GitHub or open a new pull request."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bioprov]",
   "language": "python",
   "name": "conda-env-bioprov-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
